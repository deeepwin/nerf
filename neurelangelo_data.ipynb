{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K8vzwXczDPt"
      },
      "source": [
        "# Neuralangelo Data Preperation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Author: Deeepwin   \n",
        "Date: 31.08.2023   \n",
        "\n",
        "&#9728;&#65039; Trained with renewable solar power! \n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install COLMAP from source to utilize graphics card (CUDA). Follow these [instructions](). Use this command:\n",
        "\n",
        "`cmake .. -GNinja -DCMAKE_CUDA_ARCHITECTURES=native`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify data source path:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define path to data\n",
        "DATA_PATH='/mnt/data/github/neuralangelo/datasets/car'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%cd /mnt/data/github/neuralangelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### COLMAP Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prepare folder structure in your data according to this:\n",
        "\n",
        "```\n",
        "+── $DATA_PATH/manually/created/sparse/model\n",
        "│   +── cameras.txt\n",
        "│   +── images.txt\n",
        "│   +── points3D.txt\n",
        "\n",
        "```\n",
        "\n",
        "`images.txt` contains the known camera poses, `cameras.txt` the camera type and parameter and `points3D.txt` is empty."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run sparse reconstruction to generate point clouds. With point cloud bounding box can be definied. Prepare custom data, update camera type and parameters below (take values from `cameras.txt`):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!colmap feature_extractor \\\n",
        "    --ImageReader.camera_model PINHOLE \\\n",
        "    --ImageReader.camera_params \"836.24834503, 839.37481936, 642.0, 481.0\" \\\n",
        "    --database_path $DATA_PATH/database.db \\\n",
        "    --image_path $DATA_PATH/images \\\n",
        "    --SiftExtraction.estimate_affine_shape=true \\\n",
        "    --SiftExtraction.domain_size_pooling=true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!colmap exhaustive_matcher \\\n",
        "    --database_path $DATA_PATH/database.db \\\n",
        "    --SiftMatching.guided_matching=true"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the most important step before spare reconstruction. Make sure `database.db` and `images.txt` have same image id and file name pairs. To do so, following code helps:\n",
        "\n",
        "1. Read COLMAP database and and `images.txt` with known poses\n",
        "2. Sort both according to image file name\n",
        "3. Copy image ids from database to `images.txt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from third_party.colmap.scripts.python.database import COLMAPDatabase\n",
        "\n",
        "db = COLMAPDatabase.connect(DATA_PATH + '/database.db')\n",
        "\n",
        "# read dtabase table first\n",
        "df_database = pd.read_sql_query(\"SELECT * FROM images\", db)\n",
        "db.close()\n",
        "\n",
        "# read known camera poses\n",
        "col_names = ['IMAGE_ID', 'QW', 'QX', 'QY', 'QZ', 'TX', 'TY', 'TZ', 'CAMERA_ID', 'NAME']\n",
        "df_images = pd.read_csv(DATA_PATH + '/manually/created/sparse/model/images.txt', comment='#', sep=' ', names=col_names)\n",
        "\n",
        "# sort according to images name\n",
        "df_database = df_database.sort_values(by=['name'])\n",
        "df_images = df_images.sort_values(by=['NAME'])\n",
        "\n",
        "# overwrite image ids\n",
        "df_images['IMAGE_ID'] = df_database['image_id'].values\n",
        "\n",
        "df_images.to_csv(DATA_PATH + '/manually/created/sparse/model/images.txt', sep=' ', lineterminator='\\n\\n', index=False, header=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create sparse reconstruction, unselect tri_ignore_two_view_tracks to increase number of 3D points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!colmap point_triangulator \\\n",
        "    --Mapper.tri_ignore_two_view_tracks 0 \\\n",
        "    --database_path $DATA_PATH/database.db \\\n",
        "    --image_path $DATA_PATH/images \\\n",
        "    --input_path $DATA_PATH/manually/created/sparse/model \\\n",
        "    --output_path $DATA_PATH/triangulated/sparse/model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To check, if spares model looks good open `colmap gui`:\n",
        "\n",
        "1. Import sparse model by selecting `Import Model`, select `triangulated/sparse/model` folder\n",
        "2. Store project name and select `database.db` and `images` folder\n",
        "3. To view scene, run `Bundle adjustment` with small value for `max_num_iterations` to speed up process\n",
        "\n",
        "If that looks good, proceed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is also possible to create `.bin` model directly from `.txt` model, without sparse reconstruction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 third_party/colmap/scripts/python/read_write_model.py \\\n",
        "    --input_model=$DATA_PATH/manually/created/sparse/model --input_format=.txt \\\n",
        "    --output_model=$DATA_PATH/sparse --output_format=.bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Neurelangelo Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bring data folder in right format, copy `.bin` model from `triangulated/sparse/model` folder to `sparse` folder manually. Rr run model conversion directly from `.txt` model. This way original camera poses will be used:\n",
        "\n",
        "```\n",
        "DATA_PATH\n",
        "├─ database.db      (COLMAP database)\n",
        "├─ images           (undistorted input images)\n",
        "├─ images_raw       (raw input images)\n",
        "├─ sparse           (COLMAP data from SfM)\n",
        "│  ├─ cameras.bin   (camera parameters)\n",
        "│  ├─ images.bin    (images and camera poses)\n",
        "│  ├─ points3D.bin  (sparse point clouds)\n",
        "│  ├─ 0             (a directory containing individual SfM models. There could also be 1, 2... etc.)\n",
        "│  ...\n",
        "├─ stereo (COLMAP data for MVS, not used here)\n",
        "...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate transforms.json for tnt or dtu datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for tnt just use 'tanks_and_temples' path and have at least two objects in that folder\n",
        "!bash projects/neuralangelo/scripts/preprocess_tnt.sh $DATA_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate transforms.json for custom dataset, loads `.bin` model in `sparse` folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 projects/neuralangelo/scripts/convert_data_to_json.py --data_dir $DATA_PATH --scene_type outdoor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 projects/neuralangelo/scripts/generate_config.py --sequence_name car --data_dir $DATA_PATH --scene_type outdoor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXmNCbAa7ucr"
      },
      "source": [
        "Let's inspect the results. First, we load the COLMAP data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 third_party/colmap/scripts/python/visualize_model.py --input_model=$DATA_PATH/sparse --input_format=.bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load `sparse` model and filter points like COLAMP GUI does. Without filtering it might be hard to see the object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIanVCvsXkij"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import open3d\n",
        "import json\n",
        "import plotly.graph_objs as go\n",
        "from collections import OrderedDict\n",
        "\n",
        "# import imaginaire modules.\n",
        "from projects.nerf.utils import camera, visualize\n",
        "from third_party.colmap.scripts.python.read_write_model import read_model\n",
        "\n",
        "# Read the COLMAP data.\n",
        "cameras, images, points_3D = read_model(path=f\"{DATA_PATH}/sparse\", ext=\".bin\")\n",
        "\n",
        "# convert camera poses.\n",
        "images = OrderedDict(sorted(images.items()))\n",
        "qvecs = torch.from_numpy(np.stack([image.qvec for image in images.values()]))\n",
        "tvecs = torch.from_numpy(np.stack([image.tvec for image in images.values()]))\n",
        "Rs = camera.quaternion.q_to_R(qvecs)\n",
        "poses = torch.cat([Rs, tvecs[..., None]], dim=-1)  # [N,3,4]\n",
        "print(f\"# images: {len(poses)}\")\n",
        "\n",
        "# clean up point cloud (like COLMAP GUI does)\n",
        "pcd = open3d.geometry.PointCloud()\n",
        "_xyzs = []\n",
        "_rgbs = []\n",
        "for point3D in points_3D.values():\n",
        "    if len(point3D.point2D_idxs) < 3:\n",
        "        continue\n",
        "    if point3D.error > 2.0:\n",
        "        continue\n",
        "    _xyzs.append(point3D.xyz)\n",
        "    _rgbs.append(point3D.rgb / 255)\n",
        "\n",
        "pcd.points = open3d.utility.Vector3dVector(_xyzs)\n",
        "pcd.colors = open3d.utility.Vector3dVector(_rgbs)\n",
        "\n",
        "[pcd, _] = pcd.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)\n",
        "\n",
        "# Get the sparse 3D points and the colors.\n",
        "xyzs = torch.from_numpy(np.stack(pcd.points))\n",
        "rgbs = np.stack(pcd.colors)\n",
        "# xyzs = torch.from_numpy(np.stack(_xyzs))\n",
        "# rgbs = np.stack(_rgbs)\n",
        "# xyzs = torch.from_numpy(np.stack([point.xyz for point in points_3D.values()]))\n",
        "# rgbs = np.stack([point.rgb for point in points_3D.values()])\n",
        "\n",
        "rgbs_int32 = (rgbs[:, 0] * 2**16 + rgbs[:, 1] * 2**8 + rgbs[:, 2]).astype(np.uint32)\n",
        "print(f\"# points: {len(xyzs)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize filtered point cloud with open3d."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "open3d.visualization.draw_geometries([pcd])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eewWCIIeRedG"
      },
      "source": [
        "This is where you should visualize and adjust the bounding sphere for Neuralangelo.\n",
        "- Use the forms to tune `readjust_center` and `readjust_scale` to adjust the bounding sphere.\n",
        "  - The bounding sphere should ideally *just* encapsulate the target object/scene.\n",
        "  - In the Lego toy example case, setting `readjust_scale=0.5` would be a good choice.\n",
        "- Also check whether the camera trajectory matches the expectation from the video observation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfKF43Iy0zNz"
      },
      "outputs": [],
      "source": [
        "# Visualize the bounding sphere.\n",
        "json_fname = f\"{DATA_PATH}/transforms.json\"\n",
        "with open(json_fname) as file:\n",
        "    meta = json.load(file)\n",
        "center = meta[\"sphere_center\"]\n",
        "radius = meta[\"sphere_radius\"]\n",
        "# ------------------------------------------------------------------------------------\n",
        "# These variables can be adjusted to make the bounding sphere fit the region of interest.\n",
        "# The adjusted values can then be set in the config as data.readjust.center and data.readjust.scale\n",
        "readjust_x = 0.  # @param {type:\"number\"}\n",
        "readjust_y = -0.9  # @param {type:\"number\"}\n",
        "readjust_z = 0.  # @param {type:\"number\"}\n",
        "readjust_scale = 0.23  # @param {type:\"number\"}\n",
        "readjust_center = np.array([readjust_x, readjust_y, readjust_z])\n",
        "# ------------------------------------------------------------------------------------\n",
        "center += readjust_center\n",
        "radius *= readjust_scale\n",
        "# Make some points to hallucinate a bounding sphere.\n",
        "sphere_points = np.random.randn(100000, 3)\n",
        "sphere_points = sphere_points / np.linalg.norm(sphere_points, axis=-1, keepdims=True)\n",
        "sphere_points = sphere_points * radius + center"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEOaONsbSMg2"
      },
      "source": [
        "Visualize the bounding sphere in the 3D interactive visualizer.\n",
        "- If the bounding sphere doesn't look right, readjust in the above form and rerun the code block.\n",
        "- You can modify `vis_depth` to adjust the size of the cameras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMhKrNV4Y9DE"
      },
      "outputs": [],
      "source": [
        "vis_depth = 0.2\n",
        "\n",
        "# visualize with Plotly.\n",
        "x, y, z = *xyzs.T,\n",
        "colors = rgbs\n",
        "sphere_x, sphere_y, sphere_z = *sphere_points.T,\n",
        "sphere_colors = [\"#4488ff\"] * len(sphere_points)\n",
        "traces_poses = visualize.plotly_visualize_pose(poses, vis_depth=vis_depth, xyz_length=0.02, center_size=0.01, xyz_width=0.005, mesh_opacity=0.05)\n",
        "trace_points = go.Scatter3d(x=x, y=y, z=z, mode=\"markers\", marker=dict(size=0.3, color=colors, opacity=1), hoverinfo=\"skip\")\n",
        "trace_sphere = go.Scatter3d(x=sphere_x, y=sphere_y, z=sphere_z, mode=\"markers\", marker=dict(size=0.5, color=sphere_colors, opacity=0.3), hoverinfo=\"skip\")\n",
        "traces_all = traces_poses + [trace_points, trace_sphere]\n",
        "layout = go.Layout(scene=dict(xaxis=dict(showspikes=False, backgroundcolor=\"rgba(0,0,0,0)\", gridcolor=\"rgba(0,0,0,0.1)\"),\n",
        "                              yaxis=dict(showspikes=False, backgroundcolor=\"rgba(0,0,0,0)\", gridcolor=\"rgba(0,0,0,0.1)\"),\n",
        "                              zaxis=dict(showspikes=False, backgroundcolor=\"rgba(0,0,0,0)\", gridcolor=\"rgba(0,0,0,0.1)\"),\n",
        "                              xaxis_title=\"X\", yaxis_title=\"Y\", zaxis_title=\"Z\", dragmode=\"orbit\",\n",
        "                              aspectratio=dict(x=1, y=1, z=1), aspectmode=\"data\"), height=800)\n",
        "fig = go.Figure(data=traces_all, layout=layout)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Colmap rendering and adjusted sphere."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<table><tr>\n",
        "<td> <img src=\"pics/car-1.jpg\" height=\"300\"/>  </td>\n",
        "<td> <img src=\"pics/car-2.jpg\" height=\"300\"/>  </td>\n",
        "</tr></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Mesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OUTPUT_DIR=''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!open3d draw $OUTPUT_DIR"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
