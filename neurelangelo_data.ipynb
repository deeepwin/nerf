{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K8vzwXczDPt"
      },
      "source": [
        "# Data Preperation and Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Author: Deeepwin   \n",
        "Date: 31.08.2023   \n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify data source:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define path to data\n",
        "DATA_PATH='/mnt/c/Users/WMART/Local_Repos/neuralangelo/datasets/mouse-2'\n",
        "DATA_PATH='/mnt/c/Users/WMART/Local_Repos/neuralangelo/datasets/tanks_and_temples/Ignatius'\n",
        "DATA_PATH='/mnt/c/Users/WMART/Local_Repos/neuralangelo/datasets/tanks_and_temples'\n",
        "DATA_PATH='/mnt/c/Users/WMART/Local_Repos/neuralangelo/datasets/dtu/dtu_scan65'\n",
        "DATA_PATH='/mnt/c/Users/WMART/Local_Repos/neuralangelo/datasets/car'\n",
        "DATA_PATH='/mnt/c/Users/WMART/Local_Repos/neuralangelo/datasets/dtu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate transforms.json for tnt or dtu datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for tnt just use 'tanks_and_temples' path and have at least two objects in that folder\n",
        "!bash projects/neuralangelo/scripts/preprocess_tnt.sh $DATA_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate transforms.json for custom dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 projects/neuralangelo/scripts/convert_data_to_json.py --data_dir $DATA_PATH --scene_type outdoor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python3 projects/neuralangelo/scripts/generate_config.py --sequence_name leica --data_dir $DATA_PATH --scene_type outdoor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXmNCbAa7ucr"
      },
      "source": [
        "Let's inspect the COLMAP results. First, we load the COLMAP data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xIanVCvsXkij"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import k3d\n",
        "import json\n",
        "import plotly.graph_objs as go\n",
        "from collections import OrderedDict\n",
        "# Import imaginaire modules.\n",
        "from projects.nerf.utils import camera, visualize\n",
        "from third_party.colmap.scripts.python.read_write_model import read_model\n",
        "# Read the COLMAP data.\n",
        "cameras, images, points_3D = read_model(path=f\"{DATA_PATH}/sparse\", ext=\".bin\")\n",
        "# Convert camera poses.\n",
        "images = OrderedDict(sorted(images.items()))\n",
        "qvecs = torch.from_numpy(np.stack([image.qvec for image in images.values()]))\n",
        "tvecs = torch.from_numpy(np.stack([image.tvec for image in images.values()]))\n",
        "Rs = camera.quaternion.q_to_R(qvecs)\n",
        "poses = torch.cat([Rs, tvecs[..., None]], dim=-1)  # [N,3,4]\n",
        "print(f\"# images: {len(poses)}\")\n",
        "# Get the sparse 3D points and the colors.\n",
        "xyzs = torch.from_numpy(np.stack([point.xyz for point in points_3D.values()]))\n",
        "rgbs = np.stack([point.rgb for point in points_3D.values()])\n",
        "rgbs_int32 = (rgbs[:, 0] * 2**16 + rgbs[:, 1] * 2**8 + rgbs[:, 2]).astype(np.uint32)\n",
        "print(f\"# points: {len(xyzs)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eewWCIIeRedG"
      },
      "source": [
        "This is where you should visualize and adjust the bounding sphere for Neuralangelo.\n",
        "- Use the forms to tune `readjust_center` and `readjust_scale` to adjust the bounding sphere.\n",
        "  - The bounding sphere should ideally *just* encapsulate the target object/scene.\n",
        "  - In the Lego toy example case, setting `readjust_scale=0.5` would be a good choice.\n",
        "- Also check whether the camera trajectory matches the expectation from the video observation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfKF43Iy0zNz"
      },
      "outputs": [],
      "source": [
        "json_fname = f\"{DATA_PATH}/transforms.json\"\n",
        "with open(json_fname) as file:\n",
        "    meta = json.load(file)\n",
        "center = meta[\"sphere_center\"]\n",
        "radius = meta[\"sphere_radius\"]\n",
        "# ------------------------------------------------------------------------------------\n",
        "# These variables can be adjusted to make the bounding sphere fit the region of interest.\n",
        "# The adjusted values can then be set in the config as data.readjust.center and data.readjust.scale\n",
        "readjust_x = 0.0  # @param {type:\"number\"}\n",
        "readjust_y = 0.0  # @param {type:\"number\"}\n",
        "readjust_z = 0.  # @param {type:\"number\"}\n",
        "readjust_scale = 1.0  # @param {type:\"number\"}\n",
        "readjust_center = np.array([readjust_x, readjust_y, readjust_z])\n",
        "# ------------------------------------------------------------------------------------\n",
        "center += readjust_center\n",
        "radius *= readjust_scale\n",
        "# Make some points to hallucinate a bounding sphere.\n",
        "sphere_points = np.random.randn(100000, 3)\n",
        "sphere_points = sphere_points / np.linalg.norm(sphere_points, axis=-1, keepdims=True)\n",
        "sphere_points = sphere_points * radius + center"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEOaONsbSMg2"
      },
      "source": [
        "Visualize the bounding sphere in the 3D interactive visualizer.\n",
        "- If the bounding sphere doesn't look right, readjust in the above form and rerun the code block.\n",
        "- You can modify `vis_depth` to adjust the size of the cameras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMhKrNV4Y9DE"
      },
      "outputs": [],
      "source": [
        "# @title { vertical-output: true }\n",
        "vis_depth = 0.2\n",
        "# Visualize with Plotly.\n",
        "x, y, z = *xyzs.T,\n",
        "colors = rgbs / 255.0\n",
        "sphere_x, sphere_y, sphere_z = *sphere_points.T,\n",
        "sphere_colors = [\"#4488ff\"] * len(sphere_points)\n",
        "traces_poses = visualize.plotly_visualize_pose(poses, vis_depth=vis_depth, xyz_length=0.02, center_size=0.01, xyz_width=0.005, mesh_opacity=0.05)\n",
        "trace_points = go.Scatter3d(x=x, y=y, z=z, mode=\"markers\", marker=dict(size=1, color=colors, opacity=1), hoverinfo=\"skip\")\n",
        "trace_sphere = go.Scatter3d(x=sphere_x, y=sphere_y, z=sphere_z, mode=\"markers\", marker=dict(size=0.5, color=sphere_colors, opacity=0.7), hoverinfo=\"skip\")\n",
        "traces_all = traces_poses + [trace_points, trace_sphere]\n",
        "layout = go.Layout(scene=dict(xaxis=dict(showspikes=False, backgroundcolor=\"rgba(0,0,0,0)\", gridcolor=\"rgba(0,0,0,0.1)\"),\n",
        "                              yaxis=dict(showspikes=False, backgroundcolor=\"rgba(0,0,0,0)\", gridcolor=\"rgba(0,0,0,0.1)\"),\n",
        "                              zaxis=dict(showspikes=False, backgroundcolor=\"rgba(0,0,0,0)\", gridcolor=\"rgba(0,0,0,0.1)\"),\n",
        "                              xaxis_title=\"X\", yaxis_title=\"Y\", zaxis_title=\"Z\", dragmode=\"orbit\",\n",
        "                              aspectratio=dict(x=1, y=1, z=1), aspectmode=\"data\"), height=800)\n",
        "fig = go.Figure(data=traces_all, layout=layout)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analysis of Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OUTPUT_DIR='/mnt/c/Users/WMART/Local_Repos/nerf/exports/neuralangelo-mouse-2/mouse-2_mesh.ply'\n",
        "OUTPUT_DIR='/mnt/c/Users/WMART/Local_Repos/nerf/exports/neuralangelo-ignatius/ignatius_mesh.ply'\n",
        "OUTPUT_DIR='/mnt/c/Users/WMART/Local_Repos/nerf/exports/nerfacto-mouse-2-nerfstudio/poisson_mesh.ply'\n",
        "OUTPUT_DIR='/mnt/c/Users/WMART/Local_Repos/nerf/exports/nerfacto-big-mouse-2-nerfstudio/poisson_mesh.ply'\n",
        "OUTPUT_DIR='/mnt/c/Users/WMART/Local_Repos/nerf/exports/neus-facto-dtu65/mesh.ply'\n",
        "OUTPUT_DIR='/mnt/c/Users/WMART/Local_Repos/nerf/exports/neuralangelo-dtu65-sdfstudio/mesh.ply'\n",
        "OUTPUT_DIR='/mnt/c/Users/WMART/Local_Repos/nerf/exports/neuralangelo-dtu65/dtu65_mesh.ply'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!open3d draw $OUTPUT_DIR"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
