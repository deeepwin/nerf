{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for Neuralangelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Deeepwin  \n",
    "Date: 08.07.2023 \n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Literature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related Literature:  \n",
    "\n",
    "- [Nerualangelo Supplementary](https://research.nvidia.com/labs/dir/neuralangelo/supplementary.pdf) containing details information on results.\n",
    "- [InstantNGP](https://github.com/NVlabs/instant-ngp/blob/master/docs/nerf_dataset_tips.md#COLMAP) instructions to prepare new custom image datasets using COLMAP.  \n",
    "\n",
    "  The fox example dataset can be found in original [InstantNGP repository](https://github.com/NVlabs/instant-ngp/tree/master/data/nerf/fox). InstantNGP implementation expects initial camera parameters to be provided in a `transforms.json` file in a format compatible with [the original NeRF codebase](https://www.matthewtancik.com/nerf) contains the pose information for each image.  \n",
    "\n",
    "  The script `colmap2nerf.py` can be used to convert a text colmap export `images.txt` to nerf format `transforms.json`. However, script require as well the COLMAP `cameras.txt` containing the intrinsic parameters of all cameras.\n",
    "\n",
    "- [NeRF Original Paper](https://github.com/bmild/nerf#already-have-poses) showing how to load already existing poses.\n",
    "\n",
    "- [COLMAP Output Format](https://colmap.github.io/format.html#images-txt) explains the `images.txt` which contains the poses and keypoints of all images.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarks for 3D Surface Reconstruction used by NeuralAngelo:\n",
    "\n",
    "- [Tanks and Temples](https://www.tanksandtemples.org/download/): Input is images or video. Poses are calculated from reconstruction using COLMAP into a [.log](http://redwood-data.org/indoor/fileformat.html) file format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this command in a terminal to create new conda environment:     \n",
    "\n",
    "`conda create --name sdfstudio python=3.8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pytorch with CUDA\n",
    "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires nvcc\n",
    "!conda install -y -c \"nvidia/label/cuda-11.3.1\" cuda-toolkit\n",
    "!conda install -y -c \"nvidia/label/cuda-11.3.1\" cuda-nvcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to CUDA installation\n",
    "!conda env config vars set CUDA_HOME=\"/home/martin/anaconda3/envs/sdfstudio/\"\n",
    "!conda env config vars list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check CUDA versions, must be 11.3\n",
    "!conda list cuda-nvcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# require version 9, change default version 'sudo -S update-alternatives --config gcc'\n",
    "from getpass import getpass\n",
    "p = getpass()\n",
    "!echo {p} | sudo -S apt -y install g++-9\n",
    "!echo {p} | sudo -S update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-9 9\n",
    "!echo {p} | sudo -S update-alternatives --config g++\n",
    "!echo {p} | sudo -S apt -y install gcc-9\n",
    "!echo {p} | sudo -S update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 9\n",
    "!echo {p} | sudo -S update-alternatives --config gcc\n",
    "del p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install tinycudann (you might need to run this command in separate terminal in case of an error)\n",
    "!pip install ninja git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install nerfstudio as well\n",
    "!pip install nerfstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install SDF studio\n",
    "!git clone https://github.com/autonomousvision/sdfstudio.git\n",
    "%cd sdfstudio\n",
    "!pip install -e .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinstall to ensure that torch and CUDA have same version, as previous installation steps might have changed it\n",
    "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nerf studio utilities\n",
    "!ns-install-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test SDF Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ns-download-data sdfstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model from scratch on the dtu dataset scan65, default iteration is 20000\n",
    "!ns-train neus-facto --trainer.max-num-iterations 100 --pipeline.model.sdf-field.inside-outside False --vis viewer --experiment-name neus-facto-dtu65 sdfstudio-data --data data/sdfstudio-demo-data/dtu-scan65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy paste output directory\n",
    "output_dir = 'outputs/neus-facto-dtu65/neus-facto/2023-07-28_094017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract mesh\n",
    "!ns-extract-mesh --load-config $output_dir/config.yml --output-path exports/neus-facto-dtu65/mesh.ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as point cloud, adjust export directory\n",
    "!ns-export pointcloud --load-config $output_dir/config.yml --output-dir exports/neus-facto-dtu65/ --num-points 1000 --remove-outliers True --use-bounding-box True --bounding-box-min -1 -1 -1 --bounding-box-max 1 1 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at mesh\n",
    "!open3d draw exports/neus-facto-dtu65/mesh.ply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training with Neuralangelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom data folder location\n",
    "input_dir = 'data/mine/mouse-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show list of available models\n",
    "!ns-train --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert nerfstudio (COLMAP) to sdfstudio fromat, check if conversion is correct\n",
    "!python scripts/datasets/process_nerfstudio_to_sdfstudio.py --data $input_dir --output-dir $input_dir-ns  --data-type colmap --scene-type object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For different model options see here: [Models](https://vscode.dev/github/autonomousvision/sdfstudio/blob/master/nerfstudio/configs/method_configs.py#L107). Relevant options for me are:\n",
    "\n",
    "- \"neuralangelo\": \"Implementation of Neuralangelo\"\n",
    "- \"bakedangelo\": \"Implementation of Neuralangelo with BakedSDF\"\n",
    "- \"neus-facto-angelo\": \"Implementation of Neuralangelo with neus-facto\"\n",
    "- \"instant-ngp\": \"Implementation of Instant-NGP. Recommended real-time model for bounded synthetic data.\"\n",
    "- \"mipnerf\": \"High quality model for bounded scenes. (slow)\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, use nerfstudio data fromat directly with option `nerfstudio-data`\n",
    "!ns-train neuralangelo --pipeline.model.sdf-field.inside-outside False nerfstudio-data --data $input_dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "points",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
