{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for Neuralangelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Deeepwin  \n",
    "Date: 08.07.2023 \n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Literature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related Literature:  \n",
    "\n",
    "- [Nerualangelo Supplementary](https://research.nvidia.com/labs/dir/neuralangelo/supplementary.pdf) containing details information on results.\n",
    "- [InstantNGP](https://github.com/NVlabs/instant-ngp/blob/master/docs/nerf_dataset_tips.md#COLMAP) instructions to prepare new custom image datasets using COLMAP.  \n",
    "\n",
    "  The fox example dataset can be found in original [InstantNGP repository](https://github.com/NVlabs/instant-ngp/tree/master/data/nerf/fox). InstantNGP implementation expects initial camera parameters to be provided in a `transforms.json` file in a format compatible with [the original NeRF codebase](https://www.matthewtancik.com/nerf) contains the pose information for each image.  \n",
    "\n",
    "  The script `colmap2nerf.py` can be used to convert a text colmap export `images.txt` to nerf format `transforms.json`. However, script require as well the COLMAP `cameras.txt` containing the intrinsic parameters of all cameras.\n",
    "\n",
    "- [NeRF Original Paper](https://github.com/bmild/nerf#already-have-poses) showing how to load already existing poses.\n",
    "\n",
    "- [COLMAP Output Format](https://colmap.github.io/format.html#images-txt) explains the `images.txt` which contains the poses and keypoints of all images.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarks for 3D Surface Reconstruction used by NeuralAngelo:\n",
    "\n",
    "- [Tanks and Temples](https://www.tanksandtemples.org/download/): Input is images or video. Poses are calculated from reconstruction using COLMAP into a [.log](http://redwood-data.org/indoor/fileformat.html) file format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "points",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
