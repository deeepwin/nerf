{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for Neuralangelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Deeepwin  \n",
    "Date: 08.07.2023 \n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Literature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related Literature:  \n",
    "\n",
    "- [Nerualangelo Supplementary](https://research.nvidia.com/labs/dir/neuralangelo/supplementary.pdf) containing details information on results.\n",
    "- [InstantNGP](https://github.com/NVlabs/instant-ngp/blob/master/docs/nerf_dataset_tips.md#COLMAP) instructions to prepare new custom image datasets using COLMAP.  \n",
    "\n",
    "  The fox example dataset can be found in original [InstantNGP repository](https://github.com/NVlabs/instant-ngp/tree/master/data/nerf/fox). InstantNGP implementation expects initial camera parameters to be provided in a `transforms.json` file in a format compatible with [the original NeRF codebase](https://www.matthewtancik.com/nerf) contains the pose information for each image.  \n",
    "\n",
    "  The script `colmap2nerf.py` can be used to convert a text colmap export `images.txt` to nerf format `transforms.json`. However, script require as well the COLMAP `cameras.txt` containing the intrinsic parameters of all cameras.\n",
    "\n",
    "- [NeRF Original Paper](https://github.com/bmild/nerf#already-have-poses) showing how to load already existing poses.\n",
    "\n",
    "- [COLMAP Output Format](https://colmap.github.io/format.html#images-txt) explains the `images.txt` which contains the poses and keypoints of all images.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benchmarks for 3D Surface Reconstruction used by NeuralAngelo:\n",
    "\n",
    "- [Tanks and Temples](https://www.tanksandtemples.org/download/): Input is images or video. Poses are calculated from reconstruction using COLMAP into a [.log](http://redwood-data.org/indoor/fileformat.html) file format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this command in a terminal to create new conda environment:     \n",
    "\n",
    "`conda create --name sdfstudio python=3.8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install pytorch with CUDA\n",
    "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requires nvcc\n",
    "!conda install -y -c \"nvidia/label/cuda-11.3.1\" cuda-toolkit\n",
    "!conda install -y -c \"nvidia/label/cuda-11.3.1\" cuda-nvcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to CUDA installation, CUDA is install in the environment path\n",
    "!conda env config vars set CUDA_HOME=\"/home/martin/anaconda3/envs/sdfstudio/\"\n",
    "!conda env config vars set LD_LIBRARY_PATH=/home/martin/anaconda3/envs/sdfstudio/lib:/home/martin/anaconda3/envs/sdfstudio/extras/CUPTI/lib64\n",
    "!conda env config vars list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check CUDA versions, must be 11.3\n",
    "!conda list cuda-nvcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!whereis nvcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# require version 9, change default version 'sudo -S update-alternatives --config gcc'\n",
    "from getpass import getpass\n",
    "p = getpass()\n",
    "!echo {p} | sudo -S apt -y install g++-9\n",
    "!echo {p} | sudo -S update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-9 9\n",
    "!echo {p} | sudo -S update-alternatives --config g++\n",
    "!echo {p} | sudo -S apt -y install gcc-9\n",
    "!echo {p} | sudo -S update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 9\n",
    "!echo {p} | sudo -S update-alternatives --config gcc\n",
    "del p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install tinycudann (you might need to run this command in separate terminal in case of an error)\n",
    "!pip install ninja git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install nerfstudio as well\n",
    "!pip install nerfstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install SDF studio\n",
    "!git clone https://github.com/autonomousvision/sdfstudio.git\n",
    "%cd sdfstudio\n",
    "!pip install -e .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reinstall to ensure that torch and CUDA have same version, as previous installation steps might have changed it\n",
    "!pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for compatibility\n",
    "!pip install Pillow==9.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nerf studio utilities\n",
    "!ns-install-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test SDF Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ns-download-data sdfstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model from scratch on the dtu dataset scan65, default iteration is 20000\n",
    "!ns-train neus-facto \\\n",
    "    --viewer.websocket-port 7009 \\\n",
    "    --pipeline.model.sdf-field.inside-outside False \\\n",
    "    --vis viewer \\\n",
    "    --experiment-name neus-facto-dtu65 \\\n",
    "    sdfstudio-data --data data/sdfstudio-demo-data/dtu-scan65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy paste output directory\n",
    "output_dir = 'outputs/neus-facto-dtu65/neus-facto/2023-07-28_122528'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract mesh\n",
    "!ns-extract-mesh --load-config $output_dir/config.yml --output-path exports/neus-facto-dtu65/mesh.ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export as point cloud, reduce --num-rays-per-batch if you run out of GPU memory\n",
    "!ns-export pointcloud \\\n",
    "    --load-config $output_dir/config.yml \\\n",
    "    --output-dir exports/neus-facto-dtu65/ \\\n",
    "    --num-points 100000 \\\n",
    "    --remove-outliers True \\\n",
    "    --use-bounding-box True \\\n",
    "    --bounding-box-min -1 -1 -1 \\\n",
    "    --bounding-box-max 1 1 1 \\\n",
    "    --num-rays-per-batch 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at mesh\n",
    "!open3d draw exports/neus-facto-dtu65/mesh.ply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"pics/dtu65-20000.jpg\" height=\"300\"/>  </td>\n",
    "</tr></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# give experiment a name\n",
    "data_name = 'kettle-2'\n",
    "\n",
    "# define custom data folder location\n",
    "data_input_dir = os.path.join('data', 'mine', data_name)\n",
    "data_output_dir = data_input_dir + '-ss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert nerfstudio (COLMAP) to sdfstudio format, check images if conversion was succesfull\n",
    "!python sdfstudio/scripts/datasets/process_nerfstudio_to_sdfstudio.py --data $data_input_dir --output-dir $data_output_dir --data-type colmap --scene-type object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show list of available models\n",
    "!ns-train --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For different model options see here: [Models](https://vscode.dev/github/autonomousvision/sdfstudio/blob/master/nerfstudio/configs/method_configs.py#L107). Relevant options for me are:\n",
    "\n",
    "- \"neuralangelo\": \"Implementation of Neuralangelo\"\n",
    "- \"bakedangelo\": \"Implementation of Neuralangelo with BakedSDF\"\n",
    "- \"neus-facto-angelo\": \"Implementation of Neuralangelo with neus-facto\"\n",
    "- \"instant-ngp\": \"Implementation of Instant-NGP. Recommended real-time model for bounded synthetic data.\"\n",
    "- \"mipnerf\": \"High quality model for bounded scenes. (slow)\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select model\n",
    "model_name = 'neuralangelo'\n",
    "\n",
    "# experiment id\n",
    "experiment_id = '2023-07-28_142811'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join('outputs', data_name, model_name, experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model from scratch on the dtu dataset scan65, default iteration is 20000\n",
    "!conda env config vars list\n",
    "\n",
    "# train\n",
    "!ns-train $model_name \\\n",
    "    --pipeline.model.eval-num-rays-per-chunk 1024 \\\n",
    "    --trainer.sanity-check True\\\n",
    "    --vis tensorboard \\\n",
    "    --trainer.max-num-iterations 20000 \\\n",
    "    --viewer.websocket-port 7010 \\\n",
    "    --experiment-name $data_name \\\n",
    "    nerfstudio-data --data $data_input_dir\n",
    "#\n",
    "# training options\n",
    "# \n",
    "# neus-facto\n",
    "#   --pipeline.model.sdf-field.inside-outside False \\\n",
    "#   --pipeline.model.sdf-field.bias 0.3  \\\n",
    "#   --pipeline.model.background-model mlp \\\n",
    "# nerualangelo\n",
    "#    --pipeline.model.eval-num-rays-per-chunk 1024 \\\n",
    "# Instant NGP\n",
    "#     --pipeline.model.cone-angle 0.0 \\\n",
    "#     --pipeline.model.near-plane 0.05 \\\n",
    "#     --pipeline.model.far-plane 2.5 \\\n",
    "#     --pipeline.model.alpha-thre 0.0 \\\n",
    "# MonoSDF\n",
    "    # --pipeline.model.sdf-field.use-grid-feature True \n",
    "    # --pipeline.model.sdf-field.hidden-dim 256 \\\n",
    "    # --pipeline.model.sdf-field.num-layers 2 \n",
    "    # --pipeline.model.sdf-field.num-layers-color 2 \\\n",
    "    # --pipeline.model.sdf-field.use-appearance-embedding True \n",
    "    # --pipeline.model.sdf-field.geometric-init True \\\n",
    "    # --pipeline.model.sdf-field.inside-outside True  \\\n",
    "    # --pipeline.model.sdf-field.bias 0.8 \\\n",
    "    # --pipeline.model.sdf-field.beta-init 0.1 \\\n",
    "    # --pipeline.datamanager.train-num-images-to-sample-from 1 \\\n",
    "    # --pipeline.datamanager.train-num-times-to-repeat-images 0 \\\n",
    "    # --trainer.steps-per-eval-image 5000 \\\n",
    "    # --pipeline.model.background-model none \\\n",
    "    # --pipeline.model.mono-depth-loss-mult 0.001 \\\n",
    "    # --pipeline.model.mono-normal-loss-mult 0.01 \\\n",
    "    # --pipeline.datamanager.train-num-rays-per-batch 2048 \\\n",
    "    # --include_mono_prior True \\\n",
    "    # --skip_every_for_val_split 30 \\\n",
    "# load pervious checkpoint\n",
    "#   --trainer.load-dir $output_dir/sdfstudio_models \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract mesh\n",
    "!ns-extract-mesh --load-config $output_dir/config.yml --output-path exports/$data_name/$model_name-mesh.ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at mesh\n",
    "!open3d draw exports/$data_name/$model_name-mesh.ply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ns-export pointcloud \\\n",
    "    --load-config $output_dir/config.yml \\\n",
    "    --output-dir exports/$data_name \\\n",
    "    --num-points 100000 \\\n",
    "    --remove-outliers True \\\n",
    "    --use-bounding-box True \\\n",
    "    --bounding-box-min -1 -1 -1 \\\n",
    "    --bounding-box-max 1 1 1 \\\n",
    "    --num-rays-per-batch 4096 \\\n",
    "    --rgb_output_name rgb_fine \\\n",
    "    --depth_output_name rgb_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at point cloud\n",
    "!open3d draw exports/$data_name/point_cloud.ply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Others"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "points",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
